<!DOCTYPE html>
<!--[if IE 8]> <html lang="en" class="ie8"> <![endif]-->  
<!--[if IE 9]> <html lang="en" class="ie9"> <![endif]-->  
<!--[if !IE]><!--> <html lang="en"> <!--<![endif]-->  
<head>
    <title>Aamir Mustafa's Website </title>
    <!-- Meta -->
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta name="description" content="Personal website for Aamir Mustafa">
    <meta name="author" content="Aamir Mustafa">    
    <link rel="shortcut icon" href="assets/images/profile_icon.png">  <!--favicon.ico -->
    <link href='http://fonts.googleapis.com/css?family=Lato:300,400,300italic,400italic' rel='stylesheet' type='text/css'>
    <link href='http://fonts.googleapis.com/css?family=Montserrat:400,700' rel='stylesheet' type='text/css'> 
    <!-- Global CSS -->
    <link rel="stylesheet" href="assets/plugins/bootstrap/css/bootstrap.min.css">   
    <!-- Plugins CSS -->
    <link rel="stylesheet" href="assets/plugins/font-awesome/css/font-awesome.css">
    <!-- github acitivity css -->
    <link rel="stylesheet" href="http://cdnjs.cloudflare.com/ajax/libs/octicons/2.0.2/octicons.min.css">
    <link rel="stylesheet" href="http://caseyscarborough.github.io/github-activity/github-activity-0.1.0.min.css">
    
    <!-- Theme CSS -->  
    <link id="theme-style" rel="stylesheet" href="assets/css/styles.css">
    <!-- HTML5 shim and Respond.js IE8 support of HTML5 elements and media queries -->
    <!--[if lt IE 9]>
      <script src="https://oss.maxcdn.com/libs/html5shiv/3.7.0/html5shiv.js"></script>
      <script src="https://oss.maxcdn.com/libs/respond.js/1.4.2/respond.min.js"></script>
    <![endif]-->
    
</head>

<body>
    <!-- ******HEADER****** --> 
    <header class="header">
        <div class="container">                       
            <img class="profile-image img-responsive pull-left" src="assets/images/pp_200_200.png" alt="Aamir Mustafa" />
            <div class="profile-content pull-left">
                <h1 class="name">Aamir Mustafa</h1>
                <h2 class="desc">PhD Student at University of Cambridge</h2>   
                <ul class="social list-inline">
                    <!--<li><a href="https://twitter.com/paurif"><i class="fa fa-twitter"></i></a></li> -->
                    <li><a href="https://www.linkedin.com/in/aamir-mustafa-b27969b7/"><i class="fa fa-linkedin"></i></a></li>
                    <li><a href="https://github.com/aamir-mustafa"><i class="fa fa-github"></i></a></li>
                    <li><a href="https://scholar.google.com/citations?user=fsmC_1QAAAAJ&hl=en"><i class="fa fa-graduation-cap"></i></a></li>
		  <!--  <li><a href="https://www.researchgate.net/profile/Aamir_Mustafa2"><i class="fa fa-researchgate"></i></a></li>  -->
		<li><a href="assets/cv/Resume_Aamir_Mustafa.pdf"><i class="fa fa-book"></i></a></li>


                    <!--<li><a href="mailto:xialei@cvc.uab.es"><i class="fa fa-paper-plane"></i></a></li>-->
                    <!--<li class="last-item"><a href="https://www.reddit.com/user/pribaf/"><i class="fa fa-reddit"></i></a></li>-->
                </ul> 
            </div><!--//profile-->
            <div class="profile-content pull-right" style="vertical-align: middle">
                <a href="https://www.cst.cam.ac.uk/"><img src="assets/images/uc_logo.png" alt="UC" width="150px" style="margin-top: 20px"/></a>
               <!-- <a href="http://www.inceptioniai.org/"><img src="assets/images/iiai_logo.png" alt="IIAI" width="150px" style="margin-top: 20px"/></a>   -->
               <!-- <a href="http://www.zzu.edu.cn/"><img src="assets/images/1zzu.png" alt="ZZU" width="100px" style="margin-top: 20px"/></a> -->
            </div> <!--//institution-->
        </div><!--//container-->
    </header><!--//header-->
    
    <div class="container sections-wrapper">
        <div class="row">
            <div class="primary col-md-8 col-sm-12 col-xs-12">
                
    		
		  <section class="experience section">
                    <div class="section-inner">
                        <h2 class="heading">Latest News</h2>
                        <div class="content">
			    <div class="item">
                              <h3 class="title"> 1 paper accepted in International Conference on Computer Vision (ICCV) 2019. 
                            </div><!--//item-->
                      
 				<div class="item">
                              <h3 class="title"> 1 paper accepted to IEEE Transactions on Image Processing (TIP) 2020. 
                            </div><!--//item-->

				<div class="item">
                              <h3 class="title"> 1 paper submitted to IEEE Transactions on Pattern Analysis and Machine Intelligence (T-PAMI). 
                            </div><!--//item-->
										
                        </div><!--//content-->  
                    </div><!--//section-inner-->                 
                </section><!--//section-->

		<section class="publications section">
                    <div class="section-inner">
                        <h2 class="heading">Publications</h2>
                        <div class="content">

                        <!-- ICCV 2019 -->
                        <div class="item">
                                <h3 class="title">Adversarial Defense by Restricting the Hidden Space of Deep Neural Networks</h3>
                                <!--<h3 class="desc"> <a href="https://arxiv.org/pdf/1805.01677.pdf"> [PDF] </a> <a href="https://github.com/yaxingwang/Transferring-GANs"> [Code] </a> </h3> -->
                                <ul class="social list-inline">
                                        <li><a href="https://arxiv.org/abs/1904.00887.pdf"><i class="fa fa-file-pdf-o"></i></a></li>
                                        <li><a href="https://github.com/aamir-mustafa/pcl-adversarial-defense"><i class="fa fa-github"></i></a></li>
                                    </ul> 
                                <p class="authors"><strong>Authors:</strong> Aamir Mustafa, Salman Khan, Munawar Hayat, Roland Goecke, Jianbing Shen, Ling Shao </p>
                                <p class="conference">International Conference on Computer Vision (ICCV) 2019</p>
                                <p id="Memory Replay GANs" class="abstract" style="display: none;"><strong>Abstract:</strong> Deep neural networks are vulnerable to adversarial attacks, which can fool them by adding minuscule perturbations to the input images. The robustness of existing defenses suffers greatly under white-box attack settings, where an adversary has full knowledge about the network and can iterate several times to find strong perturbations. We observe that the main reason for the existence of such perturbations is the close proximity of different class samples in the learned feature space. This allows model decisions to be totally changed by adding an imperceptible perturbation in the inputs. To counter this, we propose to class-wise disentangle the intermediate feature representations of deep networks. Specifically, we force the features for each class to lie inside a convex polytope that is maximally separated from the polytopes of other classes. In this manner, the network is forced to learn distinct and distant decision regions for each class. We observe that this simple constraint on the features greatly enhances the robustness of learned models, even against the strongest white-box attacks, without degrading the classification performance on clean images. We report extensive evaluations in both black-box and white-box attack scenarios and show significant gains in comparison to state-of-the art defenses </p>
                                <p><a class="more-link" onclick="myFunction('Memory Replay GANs')" href="javascript:void(0);"><i id="Memory Replay GANs" class="fa fa-plus"></i> Find out more</a></p>
                            </div><!--//item-->
				
                            <!-- TIP 2020 -->
                            <div class="item">
                                   <h3 class="title"> Image Super-Resolution as a Defense against Adversarial Attacks</h3>
                                   <!--<h3 class="desc"> <a href="https://arxiv.org/abs/1707.08347"> [PDF] </a> <a href="https://github.com/xialeiliu/RankIQA"> [Code] </a> </h3> -->
                                   <ul class="social list-inline">
                                        <li><a href="https://arxiv.org/abs/1901.01677.pdf"><i class="fa fa-file-pdf-o"></i></a></li>
					<li><a href="https://github.com/aamir-mustafa/super-resolution-adversarial-defense"><i class="fa fa-github"></i></a></li>
                                    </ul> 
                                <p class="authors"><strong>Authors:</strong> Aamir Mustafa, Salman Khan, Munawar Hayat, Jianbing Shen, Ling Shao</p>
                                <p class="conference"> ArXiv Preprint, 2019</p>
                                <p id="EnsemblesGAN" class="abstract" style="display: none;"><strong>Abstract:</strong> Convolutional Neural Networks have achieved significant success across multiple computer vision tasks. However, they are vulnerable to carefully crafted, human imperceptible adversarial noise patterns which constrain their deployment in critical security-sensitive systems. This paper proposes a computationally efficient image enhancement approach that provides a strong defense mechanism to effectively mitigate the effect of such adversarial perturbations. We show that the deep image restoration networks learn mapping functions that can bring off-the-manifold adversarial samples onto the natural image manifold, thus restoring classifier beliefs towards correct classes. A distinguishing feature of our approach is that, in addition to providing robustness against attacks, it simultaneously enhances image quality and retains models performance on clean images. Furthermore, the proposed method does not modify the classifier or requires a separate mechanism to detect adversarial images. The effectiveness of the scheme has been demonstrated through extensive experiments, where it has proven a strong defense in both white-box and black-box attack settings. The proposed scheme is simple and has the following advantages: (1) it does not require any model training or parameter optimization, (2) it complements other existing defense mechanisms, (3) it is agnostic to the attacked model and attack type and (4) it provides superior performance across all popular attack algorithms. </p>
                                <p><a class="more-link" onclick="myFunction('EnsemblesGAN')" href="javascript:void(0);"><i id="EnsemblesGAN" class="fa fa-plus"></i> Find out more</a></p>
                            </div><!--//item-->
				
                        <!-- DICTA 2018 -->
                        <div class="item">
                                <h3 class="title"> Prediction and Localization of Student Engagement in the Wild</h3>
                                <!--<h3 class="desc"> <a href="https://arxiv.org/pdf/1805.01677.pdf"> [PDF] </a> <a href="https://github.com/yaxingwang/Transferring-GANs"> [Code] </a> </h3> -->
                                <ul class="social list-inline">
                                        <li><a href="https://arxiv.org/abs/1804.00858.pdf"><i class="fa fa-file-pdf-o"></i></a></li>
                                        <li><a href="https://github.com/aamir-mustafa/Prediction-and-Localization-of-Student-Engagement-in-the-Wild"><i class="fa fa-github"></i></a></li>
                                    </ul> 
                                <p class="authors"><strong>Authors:</strong> Amanjot Kaur, Aamir Mustafa, Love Mehta, Abhinav Dhall </p>
                                <p class="conference"> Digital Image Computing: Techniques and Applications (DICTA) 2018</p>
                                <p id="transfer GAN" class="abstract" style="display: none;"><strong>Abstract:</strong> In this paper, we introduce a new dataset for student engagement detection and localization. Digital revolution has transformed the traditional teaching procedure and a result analysis of the student engagement in an e-learning environment would facilitate effective task accomplishment and learning. Well known social cues of engagement/disengagement can be inferred from facial expressions, body movements and gaze pattern. In this paper, student's response to various stimuli videos are recorded and important cues are extracted to estimate variations in engagement level. In this paper, we study the association of a subject's behavioral cues with his/her engagement level, as annotated by labelers. We then localize engaging/non-engaging parts in the stimuli videos using a deep multiple instance learning based framework, which can give useful insight into designing Massive Open Online Courses (MOOCs) video material. Recognizing the lack of any publicly available dataset in the domain of user engagement, a new `in the wild' dataset is created to study the subject engagement problem. The dataset contains 195 videos captured from 78 subjects which is about 16.5 hours of recording. We present detailed baseline results using different classifiers ranging from traditional machine learning to deep learning based approaches. The subject independent analysis is performed so that it can be generalized to new users. The problem of engagement prediction is modeled as a weakly supervised learning problem. The dataset is manually annotated by different labelers for four levels of engagement independently and the correlation studies between annotated and predicted labels of videos by different classifiers is reported. This dataset creation is an effort to facilitate research in various e-learning environments such as intelligent tutoring systems, MOOCs, and others.</p>
                                <p><a class="more-link" onclick="myFunction('transfer GAN')" href="javascript:void(0);"><i id="transfer GAN" class="fa fa-plus"></i> Find out more</a></p>
                            </div><!--//item-->

                            <!-- ACII 2017 -->
                            <div class="item">
                                   <h3 class="title"> Heart Rate Estimation from Facial Videos for Depression Analysis. </h3> 
                                   <!--<h3 class="desc"> <a href="https://arxiv.org/abs/1803.03095?context=cs"> [PDF]</a> <a href="https://github.com/xialeiliu/CrowdCountingCVPR18"> [Code] </a> </h3> -->
                                   <ul class="social list-inline">
                                        <li><a href="https://arxiv.org/pdf/1804.02199.pdf"><i class="fa fa-file-pdf-o"></i></a></li>
                                        <li><a href="https://github.com/yaxingwang/Mix-and-match-networks"><i class="fa fa-github"></i></a></li>
                                    </ul> 
                                <p class="authors"><strong>Authors:</strong> Aamir Mustafa, Shalini Bhatia, Munawar Hayat, Roland Goecke</p>
                                <p class="conference"> International Conference on Affective Computing and Intelligent Interaction (ACII) 2017 </p>
                                <p id="MMNet" class="abstract" style="display: none;"><strong>Abstract:</strong> Automated facial video analysis is useful in numerous health care applications. For example, spatio-temporal analysis of such videos has been previously done for assisting clinicians in the diagnosis of depression. Physiological measures, such as an individual's heart rate, provide very important cues to understand a person's mental health. Unobtrusively estimated heart rate has not been previously used to analyse individuals' mental health. In this paper, we automatically estimate heart rate activity from facial videos. We then study the association of the estimated heart rate activity with the person's mental health, as diagnosed by clinicians. Specifically, from the heart rate activity in response to watching different movies, we classify individuals as either depressed or healthy. The efficacy of the proposed scheme is demonstrated by experimental evaluations on a clinically validated dataset. Our results suggest unobtrusively estimated heart rate to be very effective for depression analysis.</p>
                                <p><a class="more-link" onclick="myFunction('MMNet')" href="javascript:void(0);"><i id="liu2018leveraging" class="fa fa-plus"></i> Find out more</a></p>
                            </div><!--//item-->
				


                           
                        </div><!--//content-->  
                    </div><!--//section-inner-->                 
                </section><!--//section-->
               
                <section class="experience section">
                    <div class="section-inner">
                        <h2 class="heading">Experience</h2>
                        <div class="content">

                            <div class="item">
                                <h3 class="title"> PhD Student - <span class="place"><a href="https://www.cl.cam.ac.uk/research/rainbow/people/">Computer Science Dept. University of Cambridge </a></span> <span class="year">(Oct 2019 - Present)</span></h3>
                                <p> Leveraging the use of semi-supervised learing for image to image translation. .</p>
                            </div><!--//item-->
				
                            <div class="item">
                                <h3 class="title"> Computer Vision Research Intern - <span class="place"><a href="http://www.inceptioniai.org">Inception Institute of Artificial Intelligence </a></span> <span class="year">(Sep 2018 - Sep 2019)</span></h3>
                                <p> Working on making deep neural networks robust against adversarial attacks.</p>
                            </div><!--//item-->
                            
                            <div class="item">
                                <h3 class="title"> Computer Vision Research Intern - <span class="place"><a href="http://iitrpr.ac.in/lasii/index.html"> Indian Institute of Technology, Ropar </a></span> <span class="year">(Dec 2017 - Mar 2018)</span></h3>
                                <p> Worked on prediction and localization of student engagement in response to a stimuli video (e-learning environment) from facial expressions using Deep Multi-Instance Learning. </p>
                            </div><!--//item-->

                            <div class="item">
                                <h3 class="title"> Machine Learning Research Intern - <span class="place"><a href="http://www.uab.cat/"> University of Canberra, Australia </a></span> <span class="year">(Dec 2016 - Feb 2017)</span></h3>
                                <p> Estimation of Heart rate of different individuals and its variations over the span of video from their facial videos by extracting plethysmograph (PG) signals from green channel of the frames. Considering heart rate as extracted feature, individuals are classified into two categories - healthy controls and depressed patients using a linear SVM classifier. </p>
                            </div><!--//item-->
			    
                            
                        </div><!--//content-->  
                    </div><!--//section-inner-->                 
                </section><!--//section-->

                <section class="about section">
                    <div class="section-inner">
                        <h2 class="heading">Bio</h2>
                        <div class="content">
				<p> I did my bachelors degree in Electronics and Communication Engineering from National Institute of Technology (NIT), Srinagar, India. During my under-grad I did a couple of research intersnhips at University of Canberra, Australia and Indian Institute of Technology (IIT) Ropar. Later I am worked as a computer vision research intern at Inception Institute of Artificial Intelligence (IIAI), Abu Dhabi, UAE for a year. Currently I am working as a Research Assistant/ PhD candidate at University of Cambridge, UK on Applications of Machine/Deep Learning in Computer Graphics.   </p>
                           <!-- <p>I completed M.Sc. degrees in Signal Processing  from the ZhengZhou University (ZZU). Currently, I am pursuing the Ph.D. degree under the supervision of Dr. Joost van de Weijer starting in 2015. I have worked on a wide variety of projects including images for Encoder-decoder, Transfer Learning, Domain Adaptation, Lifelong Learning.</p> -->

                        </div><!--//content-->
                    </div><!--//section-inner-->                 
                </section><!--//section-->

            </div><!--//primary-->

            <div class="secondary col-md-4 col-sm-12 col-xs-12">
                 <aside class="info aside section">
                    <div class="section-inner">
                        <h2 class="heading sr-only">Basic Information</h2>
                        <div class="content">
                            <ul class="list-unstyled">
                                <li>
                                    <table style="display: inline;">
                                        <tr>
                                            <td>
                                                <i class="fa fa-globe"></i><span class="sr-only">Location:</span>
                                             <!--   <br> <br> <br> -->
                                            </td>
                                            <td>
                                                SE18 The Computer Laboratory William Gates Building 
						    15 JJ Thompson Avenue <br>
                                                Cambridge CB3 0FD  <!--<br>  -->
                                                <!--08193, Bellaterra, Barcelona, Catalunya -->
                                            </td>
                                        </tr>
                                    </table>
                                </li>
                                <!-- <li><i class="fa fa-phone"></i><span class="sr-only">Phone:</span>+34 93 581 1828</li> -->
                                <li><i class="fa fa-envelope-o"></i><span class="sr-only">Email:</span>am2806@cam.ac.uk <!-- &lt;at&gt; cvc.uab.es --></li>
                                <!-- <li><i class="fa fa-link"></i><span class="sr-only">Website:</span><a href="http://www.cvc.uab.es/LAMP/">http://www.cvc.uab.es/LAMP/</a></li> -->
                            </ul>
                        </div> <!--//content-->  
                    </div><!--//section-inner-->                 
                </aside><!--//aside-->
 
		<aside class="skills aside section">
                    <div class="section-inner">
                        <h2 class="heading">Deep Learning Libraries</h2>
                        <div class="content">
                            <div class="skillset">

				<div class="item">
                                    <h3 class="level-title">PyTorch<span class="level-label">Proficient</span></h3>
                                    <div class="level-bar">
                                        <div class="level-bar-inner" data-level="95%">
                                        </div>                                      
                                    </div><!--//level-bar-->                                 
                                </div><!--//item-->
				    
                                <div class="item">
                                    <h3 class="level-title">Tensorflow<span class="level-label">Intermediate</span></h3>
                                    <div class="level-bar">
                                        <div class="level-bar-inner" data-level="80%">
                                        </div>                                      
                                    </div><!--//level-bar-->                                 
                                </div><!--//item-->
				    
                                <div class="item">
                                    <h3 class="level-title">Keras<span class="level-label">Proficient</span></h3>
                                    <div class="level-bar">
                                        <div class="level-bar-inner" data-level="95%">
                                        </div>                                      
                                    </div><!--//level-bar-->                                 
                                </div><!--//item-->
				    
                                                                
                                <!--<p><a class="more-link" href="#"><i class="fa fa-external-link"></i> More on Coderwall</a></p> -->
                            </div>              
                        </div><!--//content-->  
                    </div><!--//section-inner-->                 
                </aside><!--//section-->
		    
                <aside class="skills aside section">
                    <div class="section-inner">
                        <h2 class="heading">Coding</h2>
                        <div class="content">
                            <div class="skillset">

								    
                                <div class="item">
                                    <h3 class="level-title">Python<span class="level-label">Proficient</span></h3>
                                    <div class="level-bar">
                                        <div class="level-bar-inner" data-level="95%">
                                        </div>                                      
                                    </div><!--//level-bar-->                                 
                                </div><!--//item-->
                                
                                <div class="item">
                                    <h3 class="level-title">Matlab<span class="level-label" data-toggle="tooltip" data-placement="left" data-animation="true" title="You can use the tooltip to add more info...">Intermediate</span></h3>
                                    <div class="level-bar">
                                        <div class="level-bar-inner" data-level="85%">
                                        </div>                                      
                                    </div><!--//level-bar-->                                 
                                </div><!--//item-->
                                
				   <div class="item">
                                    <h3 class="level-title">C, C++<span class="level-label">Used it</span></h3>
                                    <div class="level-bar">
                                        <div class="level-bar-inner" data-level="50%">
                                        </div>                                      
                                    </div><!--//level-bar-->                                 
                                </div><!--//item-->
                                
                                <!--<p><a class="more-link" href="#"><i class="fa fa-external-link"></i> More on Coderwall</a></p> -->
                            </div>              
                        </div><!--//content-->  
                    </div><!--//section-inner-->                 
                </aside><!--//section-->
                               
                <aside class="education aside section">
                    <div class="section-inner">
                        <h2 class="heading">Education</h2>
                        <div class="content">
                            <div class="item">                      
                                <h3 class="title"><i class="fa fa-graduation-cap"></i> PhD in Computer Graphics</h3>
                                <h4 class="university"> University of Cambridge</h4>
                                <!--<h4 class="university">Rainbow Group</h4> -->
                                <h4 class="year">(2019-Now)</h4>
                           </div><!--//item-->
                           <div class="item">                      
                                <h3 class="title"><i class="fa fa-graduation-cap"></i> B.Tech in Electronics Engineering</h3>
                                <h4 class="university"> National Institute of Technology, Srinagar </h4>
                                <h4 class="year">(2014-2018)</h4>
                            </div><!--//item-->

                        </div><!--//content-->
                    </div><!--//section-inner-->
                </aside><!--//section--> 
                            
                <aside class="languages aside section">
                    <div class="section-inner">
                        <h2 class="heading">Languages</h2>
                        <div class="content">
                            <ul class="list-unstyled">
                                <li class="item">
                                    <span class="title"><strong>English:</strong></span>
                                    <span class="level"> Native Speaker <br class="visible-xs"/><i class="fa fa-star"></i> <i class="fa fa-star"></i> <i class="fa fa-star"></i> <i class="fa fa-star"></i> <i class="fa fa-star"></i> </span>
                                </li><!--//item-->
                            
				<li class="item">
                                    <span class="title"><strong>Urdu:</strong></span>
                                    <span class="level"> Native Speaker <br class="visible-xs"/><i class="fa fa-star"></i> <i class="fa fa-star"></i> <i class="fa fa-star"></i> <i class="fa fa-star"></i> <i class="fa fa-star"></i> </span>
                                </li><!--//item-->
                               
			
				<li class="item">
                                    <span class="title"><strong>Hindi:</strong></span>
                                    <span class="level"> Intermediate <br class="visible-sm visible-xs"/><i class="fa fa-star"></i> <i class="fa fa-star"></i> <i class="fa fa-star"></i> <i class="fa fa-star"></i> <i class="fa fa-star-o" aria-hidden="true"></i> </span>
                                </li><!--//item-->
					
                            </ul>
                        </div><!--//content-->
                    </div><!--//section-inner-->
                </aside><!--//section-->



               <!-- <aside class="habits aside section"> -->
                   <!-- <div class="section-inner"> -->
                   <!--     <h2 class="heading">Hobbies</h2> -->
                   <!--     <div class="content"> -->
                   <!--         <p>The key parts of my spare time are working out, which is good for me from boosting my mood to improving my life,  as well as cooking which leads to healthy life and harmonious family. Dance, my favorite sport,  offers a way to improve strength and flexibility, which helps keep muscles and joints healthy. Shaking body with the melody of music will express my unknown sides. Besides, I also enjoy playing basketball to make new friends with different backgrounds and cultures </p> -->
                  <!--      </div> --> <!--//content-->
                <!--    </div>  -->  <!--//section-inner-->
              <!--  </aside>  -->  <!--//section-->





            </div><!--//secondary-->    
        </div><!--//row-->
    </div><!--//masonry-->

    <!-- ******GO TO TOP****** -->
    <button onclick="topFunction()" id="go2top" title="Go to top"><i class="fa fa-address-card" style="font-size: 2em"></i></button> 

    <!-- ******FOOTER****** --> 
    <footer class="footer">
        <div class="container text-center">
                <small class="copyright">Designed with <i class="fa fa-heart"></i> by <a href="http://themes.3rdwavemedia.com" target="_blank">3rd Wave Media</a> for developers under the <a class="dotted-link" href="http://creativecommons.org/licenses/by/3.0/" target="_blank">Creative Commons Attribution 3.0 License</a> <a href="http://themes.3rdwavemedia.com/website-templates/free-responsive-website-template-for-developers/" target="_blank"><i class="fa fa-download"></i></a></small>
        </div><!--//container-->
    </footer><!--//footer-->

    <!-- Javascript -->          
    <script type="text/javascript" src="assets/plugins/jquery-1.11.1.min.js"></script>
    <script type="text/javascript" src="assets/plugins/jquery-migrate-1.2.1.min.js"></script>
    <script type="text/javascript" src="assets/plugins/bootstrap/js/bootstrap.min.js"></script>    
    <script type="text/javascript" src="assets/plugins/jquery-rss/dist/jquery.rss.min.js"></script> 
    <script>
	function myFunction(id) {
	    var x = document.getElementById(id);
            var b = document.getElementById("b_".concat(id));
	    if (x.style.display === 'none') {
		x.style.display = 'block';
                b.className = "fa fa-minus"
	    } else {
		x.style.display = 'none';
		b.className = "fa fa-plus"
	    }
	}
    </script>
    <!-- GO TO TOP -->
    <script>
    // When the user scrolls down 20px from the top of the document, show the button
    window.onscroll = function() {scrollFunction()};

    function scrollFunction() {
        if (document.body.scrollTop > 2000 || document.documentElement.scrollTop > 2000) {
            document.getElementById("go2top").style.display = "block";
        } else {
            document.getElementById("go2top").style.display = "none";
        }
    }

    // When the user clicks on the button, scroll to the top of the document
    function topFunction() {
        document.body.scrollTop = 0; // For Chrome, Safari and Opera
        document.documentElement.scrollTop = 0; // For IE and Firefox
    } 
    </script>
    <!-- github activity plugin -->
    <script type="text/javascript" src="http://cdnjs.cloudflare.com/ajax/libs/mustache.js/0.7.2/mustache.min.js"></script>
    <script type="text/javascript" src="http://caseyscarborough.github.io/github-activity/github-activity-0.1.0.min.js"></script>
    <!-- custom js -->
    <script type="text/javascript" src="assets/js/main.js"></script>            
</body>
</html> 

